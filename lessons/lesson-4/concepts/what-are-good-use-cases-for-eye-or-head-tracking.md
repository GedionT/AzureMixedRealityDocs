# What are good use cases for eye or head tracking?

## Eye Tracking

**Object placement**: Information about where and what a user looks at provides a powerful context for other inputs, such as voice, hands and controllers. This can be used for various tasks. For example, this can range from quickly and effortlessly targeting across the scene by simply looking at a hologram and saying "select" or "put this...", then looking over to where the user wants to place the hologram and say "...there".

**Engaging with virtual agents**: Information about what users look at could be used to enhance engagement with embodied virtual agents and interactive holograms. For instance, virtual agents might adapt available options and their behavior, based on currently viewed content.

**Auto Scroll**: Eye-gaze-based auto scroll could be used when the user reads a long text which automatically starts scrolling once the user gets to the bottom of the textbox. This keeps the user in the flow of reading, without lifting a finger. A key aspect of this is that the scrolling speed adapts to the reading speed of the user. 

**Zoom and Pan**: Eye-supported zoom and pan enables the user to feel like diving exactly toward what they are focused on. Triggering and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed. Once zoomed in, the user can smoothly follow, for example, the course of a street to explore their neighborhood by using their eye-gaze.

**Smart Notifications**: If using notifications in an app, you could take into account what a user is paying attention to and offset notifications from where the user is currently gazing. This limits distractions and automatically dismisses them once the user is finished reading.

**Attentive Hologram**: You could create attentive holograms which are holograms that subtly react when being gazed upon. This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.

**Remote eye-gaze visualization**: Visualize what remote collaborators are looking at to be able to provide immediate feedback and facilitate more accurate information processing.

**User research studies**: Attention tracking can help researchers get more insights into how users perceive and engage with the natural environment, without interfering, to design more instinctual human-computer-interactions. Eye tracking can provide information that is not directly articulated by participants in the study, which otherwise might be easily missed by the researcher.

**Training and performance monitoring**: Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow. Eye tracking can provide natural, real-time and objective information to help improve training, productivity, and safety in the workplace.

**Design evaluations, marketing and consumer research**: Eye tracking enables commercial companies to perform marketing and consumer studies in real-world environments or analyze what captures a userâ€™s attention to improve product or space design.

## Head Tracking

The head gaze vector has been shown repeatedly to be usable for targeting small objects but often works best for targeting large objects.